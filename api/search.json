[{"id":"4ad643c3b688b2b0038ebbf29d874ce0","title":"Java面试题收集整理","content":"Java 架构师面试问题完善答案1. 千万级用户电商系统架构设计整体架构选型微服务架构 + 分层设计\n\n接入层：Nginx&#x2F;LVS 负载均衡 + CDN\n网关层：Spring Cloud Gateway&#x2F;Kong，统一鉴权、限流、路由\n业务层：微服务集群（用户、商品、订单、支付、库存等）\n数据层：MySQL 主从+分库分表 + Redis 集群 + MQ\n监控层：APM 监控 + 日志收集 + 告警系统\n\n数据库设计策略分库分表方案：\n\n用户库：按 user_id 取模分 16 库，每库分 64 表 → 支持 10 亿用户\n订单库：按 user_id 分库（保证用户订单在同一库），按订单时间分表\n商品库：按商品类目分库，热门商品单独缓存\n读写分离：主库写入，从库查询，延迟控制在 100ms 内\n\n数据一致性：\n\n强一致性：订单+支付（2PC&#x2F;TCC）\n最终一致性：积分+优惠券（消息队列异步处理）\n\n缓存架构多层缓存设计：\n\nL1 - 本地缓存：JVM 内 Caffeine，缓存热点数据（商品基础信息）\nL2 - 分布式缓存：Redis 集群，主从+哨兵模式\nL3 - CDN：静态资源和页面缓存\n\nRedis 集群方案：\n\n部署模式：3 主 3 从 + 哨兵集群\n数据分片：一致性 Hash，支持动态扩容\n缓存策略：\n热点商品：缓存 1 小时，添加随机 30 分钟避免雪崩\n用户信息：缓存 30 分钟\n库存信息：缓存 5 分钟，结合本地缓存\n\n\n\n高并发保障限流策略：\n\n网关限流：令牌桶算法，按 IP&#x2F;用户&#x2F;接口多维度限流\n服务限流：Sentinel&#x2F;Hystrix 熔断降级\n数据库限流：连接池大小控制，慢查询监控\n\n容量规划：\n\n应用服务器：单机 2000QPS，部署 20+节点\n数据库：主库写入 5000TPS，从库读取 20000QPS\nRedis：单节点 10 万 QPS，集群总计 60 万 QPS\n\n2. 微服务拆分边界设计服务拆分原则按业务领域拆分（DDD）：\n\n用户域：用户中心服务（注册、登录、个人信息）\n商品域：商品服务（商品信息、分类、搜索）+ 库存服务\n交易域：订单服务 + 购物车服务\n支付域：支付服务（多渠道支付）\n营销域：优惠券服务 + 积分服务\n基础域：通知服务、文件服务、配置中心\n\n服务间通信同步调用：REST API（OpenFeign）\n\n用户信息查询、商品详情查询等异步通信：RocketMQ\n订单状态变更、支付成功通知、库存变更等\n\n3. 缓存深度设计缓存使用场景\n商品信息缓存：热门商品基础信息，缓存命中率&gt;95%\n用户会话缓存：用户登录状态、购物车信息\n库存缓存：实时库存信息，配合数据库双写\n搜索结果缓存：热门关键词搜索结果\n页面片段缓存：商品详情页 HTML 片段\n\n缓存问题解决方案缓存击穿：\n1234567891011121314151617181920212223// 分布式锁+双重检查public Object getFromCache(String key) &#123;    Object value = redis.get(key);    if (value == null) &#123;        String lockKey = &quot;lock:&quot; + key;        if (redis.setIfAbsent(lockKey, &quot;1&quot;, Duration.ofSeconds(10))) &#123;            try &#123;                value = redis.get(key); // 双重检查                if (value == null) &#123;                    value = loadFromDB(key);                    redis.setEx(key, value, Duration.ofMinutes(30));                &#125;            &#125; finally &#123;                redis.delete(lockKey);            &#125;        &#125; else &#123;            // 等待并重试            Thread.sleep(50);            return getFromCache(key);        &#125;    &#125;    return value;&#125;\n\n缓存雪崩：\n\n缓存过期时间添加随机值（基础时间 ± 30%）\n多级缓存设计，避免单点故障\n熔断机制，缓存不可用时降级到数据库\n\n缓存穿透：\n\n布隆过滤器预判断\n空值缓存（短时间）\n参数校验，避免恶意请求\n\n4. JVM 调优详细方案8G 内存服务器 JVM 参数设置12345678910-Xms4g -Xmx4g                    # 堆内存4G（物理内存50%）-XX:MetaspaceSize=256m           # 元空间初始大小-XX:MaxMetaspaceSize=512m        # 元空间最大大小-XX:+UseG1GC                     # 使用G1垃圾收集器-XX:MaxGCPauseMillis=100         # GC停顿时间目标100ms-XX:G1HeapRegionSize=16m         # G1区域大小-XX:+UseStringDeduplication      # 字符串去重-XX:+PrintGCDetails              # 打印GC详情-XX:+PrintGCTimeStamps           # 打印GC时间戳-Xloggc:/path/to/gc.log         # GC日志文件\n\nJVM 性能问题排查工具监控工具：\n\njstat：实时查看 GC 情况\njmap：内存 dump 分析\njstack：线程堆栈分析\nMAT&#x2F;VisualVM：内存分析\nArthas：在线诊断工具\n\n典型问题和解决方案：\n\nFull GC 频繁：调整新生代比例，优化对象生命周期\n内存泄漏：MAT 分析 dump 文件，定位大对象\nCPU 高：jstack 分析线程状态，定位热点代码\n\n5. 分布式事务完整方案Saga 模式状态机设计123456789101112131415161718192021222324252627282930&#123;  &quot;name&quot;: &quot;orderSagaStateMachine&quot;,  &quot;startState&quot;: &quot;DeductStock&quot;,  &quot;states&quot;: [    &#123;      &quot;name&quot;: &quot;DeductStock&quot;,      &quot;serviceTask&quot;: &quot;stockService.deduct&quot;,      &quot;compensateState&quot;: &quot;RestoreStock&quot;,      &quot;next&quot;: &quot;CreateOrder&quot;    &#125;,    &#123;      &quot;name&quot;: &quot;CreateOrder&quot;,      &quot;serviceTask&quot;: &quot;orderService.create&quot;,      &quot;compensateState&quot;: &quot;CancelOrder&quot;,      &quot;next&quot;: &quot;DeductBalance&quot;    &#125;,    &#123;      &quot;name&quot;: &quot;DeductBalance&quot;,      &quot;serviceTask&quot;: &quot;paymentService.deduct&quot;,      &quot;compensateState&quot;: &quot;RestoreBalance&quot;,      &quot;next&quot;: &quot;AddPoints&quot;    &#125;,    &#123;      &quot;name&quot;: &quot;AddPoints&quot;,      &quot;serviceTask&quot;: &quot;pointService.add&quot;,      &quot;compensateState&quot;: &quot;DeductPoints&quot;,      &quot;next&quot;: &quot;Succeed&quot;    &#125;  ]&#125;\n\n补偿机制设计幂等性保证：每个服务操作和补偿操作都要支持幂等补偿顺序：严格按照执行顺序的逆序进行补偿异常处理：补偿失败时进入人工处理队列\n6. 线上问题应急处理流程故障响应流程（SRE 标准）第一阶段：止血（5 分钟内）\n\n快速判断影响面：监控大盘查看影响范围\n紧急措施：\n限流&#x2F;熔断止损\n快速回滚可疑变更\n扩容资源（如果是容量问题）\n\n\n\n第二阶段：定位（30 分钟内）\n\n日志分析：ELK 检索关键错误信息\n监控分析：CPU、内存、网络、数据库指标\n链路追踪：Skywalking&#x2F;Zipkin 分析慢请求\n数据库分析：慢查询日志、锁等待情况\n\n第三阶段：修复（2 小时内）\n\n根因修复：代码修复或配置调整\n灰度验证：小流量验证修复效果\n全量发布：确认无误后全量上线\n\n第四阶段：复盘（24 小时内）\n\n故障时间线梳理\n根本原因分析（5 个为什么）\n改进措施制定\n预防机制建立\n\n7. 健康检查机制完整实现Spring Boot 自定义健康检查123456789101112131415161718192021222324252627282930313233343536373839404142@Componentpublic class DependencyHealthIndicator implements HealthIndicator &#123;    @Autowired    private RedisTemplate redisTemplate;    @Autowired    private RocketMQTemplate rocketMQTemplate;    @Override    public Health health() &#123;        try &#123;            // Redis健康检查            redisTemplate.opsForValue().get(&quot;health_check&quot;);            // MQ健康检查            // 发送测试消息验证连通性            return Health.up()                .withDetail(&quot;redis&quot;, &quot;UP&quot;)                .withDetail(&quot;mq&quot;, &quot;UP&quot;)                .build();        &#125; catch (Exception e) &#123;            return Health.down()                .withDetail(&quot;error&quot;, e.getMessage())                .build();        &#125;    &#125;&#125;@Componentpublic class StartupHealthChecker implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123;    @Override    public void onApplicationEvent(ContextRefreshedEvent event) &#123;        // 启动时强制健康检查，失败则终止启动        Health health = healthIndicator.health();        if (health.getStatus() != Status.UP) &#123;            throw new RuntimeException(&quot;依赖服务不可用，启动失败: &quot; + health.getDetails());        &#125;    &#125;&#125;\n\n运行时健康检查1234567891011121314151617181920212223242526272829303132333435@Componentpublic class RuntimeHealthChecker &#123;    private volatile boolean healthy = true;    @Scheduled(fixedRate = 30000) // 30秒检查一次    public void checkDependencies() &#123;        try &#123;            // 检查关键依赖            checkRedis();            checkDatabase();            checkMQ();            healthy = true;        &#125; catch (Exception e) &#123;            healthy = false;            // 触发告警            alertService.sendAlert(&quot;依赖服务异常: &quot; + e.getMessage());        &#125;    &#125;    // 请求拦截器，不健康时拒绝服务    @Component    public class HealthInterceptor implements HandlerInterceptor &#123;        @Override        public boolean preHandle(HttpServletRequest request,                               HttpServletResponse response,                               Object handler) &#123;            if (!runtimeHealthChecker.isHealthy()) &#123;                response.setStatus(503); // Service Unavailable                return false;            &#125;            return true;        &#125;    &#125;&#125;\n\n8. 分布式限流系统设计整体架构组件设计：\n\n限流网关：基于 Redis+Lua 脚本的分布式限流\n配置中心：Nacos&#x2F;Apollo 动态配置管理\n监控告警：Prometheus+Grafana 实时监控\n\n核心算法实现1234567891011121314151617181920-- Redis Lua脚本实现滑动窗口限流local key = KEYS[1]           -- 限流keylocal window = tonumber(ARGV[1])  -- 时间窗口（秒）local limit = tonumber(ARGV[2])   -- 限流阈值local now = tonumber(ARGV[3])     -- 当前时间戳-- 清理过期数据redis.call(&#x27;ZREMRANGEBYSCORE&#x27;, key, 0, now - window * 1000)-- 获取当前窗口内请求数local current = redis.call(&#x27;ZCARD&#x27;, key)if current &lt; limit then    -- 允许请求，记录当前请求    redis.call(&#x27;ZADD&#x27;, key, now, now .. &#x27;-&#x27; .. math.random())    redis.call(&#x27;EXPIRE&#x27;, key, window + 1)    return &#123;1, limit - current - 1&#125; -- 允许，返回剩余配额else    return &#123;0, 0&#125; -- 拒绝end\n\n多维度限流实现123456789101112131415161718192021222324252627282930313233343536@Servicepublic class DistributedRateLimiter &#123;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    private DefaultRedisScript&lt;List&gt; script = new DefaultRedisScript&lt;&gt;();    public boolean tryAcquire(String resource, String identifier,                             int limit, int windowSize) &#123;        // 构造多维度限流key        String key = String.format(&quot;rate_limit:%s:%s&quot;, resource, identifier);        List&lt;String&gt; keys = Collections.singletonList(key);        List&lt;String&gt; args = Arrays.asList(            String.valueOf(windowSize),            String.valueOf(limit),            String.valueOf(System.currentTimeMillis())        );        List result = redisTemplate.execute(script, keys, args.toArray());        return (Integer) result.get(0) == 1;    &#125;&#125;// 使用示例@RestControllerpublic class OrderController &#123;    @PostMapping(&quot;/order&quot;)    @RateLimit(key = &quot;#request.userId&quot;, limit = 100, window = 60) // 用户级限流    @RateLimit(key = &quot;api:/order&quot;, limit = 10000, window = 60)    // 接口级限流    public Result createOrder(@RequestBody CreateOrderRequest request) &#123;        // 业务逻辑    &#125;&#125;\n\n动态配置管理12345678910111213141516171819@Component@ConfigurationProperties(prefix = &quot;rate-limit&quot;)@RefreshScope // 支持动态刷新public class RateLimitConfig &#123;    private Map&lt;String, LimitRule&gt; rules = new HashMap&lt;&gt;();    public static class LimitRule &#123;        private int limit;      // 限流阈值        private int windowSize; // 时间窗口        private String strategy; // 限流策略：IP/USER/API    &#125;    @EventListener    public void onConfigChange(RefreshEvent event) &#123;        // 配置变更时重新加载限流规则        log.info(&quot;限流配置已更新: &#123;&#125;&quot;, rules);    &#125;&#125;\n\n9. 系统监控体系设计监控维度应用层监控：\n\nQPS&#x2F;TPS：接口调用量和成功率\n响应时间：P99、P95、P50 响应时间\n错误率：4xx、5xx 错误统计\n线程池状态：活跃线程数、队列长度\n\n基础设施监控：\n\n服务器：CPU、内存、磁盘、网络\n数据库：连接数、慢查询、锁等待\n缓存：命中率、内存使用、连接数\n消息队列：消息堆积、消费速率\n\n业务监控：\n\n核心业务指标：订单量、支付成功率、用户活跃度\n资金安全：异常交易监控\n用户体验：页面加载时间、关键路径成功率\n\n告警策略分级告警：\n\nP0：核心服务不可用（立即电话+短信）\nP1：重要功能异常（15 分钟内响应）\nP2：性能指标异常（1 小时内响应）\nP3：非关键问题（工作时间处理）\n\n智能告警：\n\n异常检测算法：基于历史数据的异常波动检测\n告警收敛：同类告警 5 分钟内只发送一次\n升级机制：P1 问题 30 分钟无响应自动升级为 P0\n\n10. 技术选型权衡实例消息队列技术选型案例业务场景：订单系统消息通知\n候选方案：\n\nRabbitMQ：功能丰富，支持多种消息模式\nRocketMQ：阿里开源，适合高并发场景\nKafka：高吞吐，适合日志收集\n\n决策矩阵：\n\n\n\n维度\nRabbitMQ\nRocketMQ\nKafka\n\n\n\n性能\n中\n高\n最高\n\n\n可靠性\n高\n高\n中\n\n\n易用性\n高\n中\n低\n\n\n运维成本\n低\n中\n高\n\n\n团队熟悉度\n高\n低\n中\n\n\n最终选择：RocketMQ理由：业务对性能要求高，可靠性要求高，团队愿意投入学习成本\n11. 架构师核心能力模型技术能力演进路径高级开发 → 架构师转变：\n\n技术深度 → 技术广度\n\n从精通某个技术栈 → 掌握多技术栈选型能力\n关注性能优化 → 关注系统整体架构\n\n\n解决问题 → 预防问题\n\n从解决当前 bug → 设计可扩展、可维护的系统\n从个人效率 → 团队整体效率\n\n\n技术视角 → 业务+技术视角\n\n理解业务需求，技术服务于业务\n成本意识，ROI 评估能力\n\n\n个人贡献 → 团队赋能\n\n技术方案设计与推动\n团队技术能力提升\n跨部门协作能力\n\n\n\n能力建设建议短期（1 年）：\n\n深入学习分布式系统理论（CAP、BASE 等）\n实践容器化和云原生技术\n提升系统设计和性能调优能力\n\n中期（2-3 年）：\n\n培养业务理解能力，参与产品设计\n建立技术团队影响力，输出技术方案\n学习团队管理和项目管理\n\n长期（3-5 年）：\n\n成为某个技术领域的专家\n具备从 0 到 1 构建大型系统的能力\n培养技术前瞻性，把握技术发展趋势\n\n","slug":"java/Java面试收集-1","date":"2025-09-01T07:00:00.000Z","categories_index":"java","tags_index":"面试,java","author_index":"Gao"},{"id":"c5e09afc7ded2f44e395222316bd8c7e","title":"Cloudflared Tunnel ipv6","content":"Cloudflared Tunnel ipv61docker run cloudflare/cloudflared:latest tunnel --no-autoupdate run --token eyJhIjoiY2E0…………\n\n修改为\n\n1docker run -d --dns  2606:4700:4700::1111   --network host -d cloudflare/cloudflared:latest   tunnel  --edge-ip-version 6    --no-autoupdate run  --token eyJhIjoiY2E0OD……\n主要是要添加 –edge-ip-version 6network host 一定要加上\n","slug":"cloudflare/cloudflared tunnel","date":"2024-12-01T16:00:00.000Z","categories_index":"Cloudflare","tags_index":"Cloudflared","author_index":"Gao"},{"id":"3c89efb75a3b30889d5957c58adb78b4","title":"Linux安装ohmyzsh","content":"1. 安装 zsh1apt install zsh\n\n设置默认终端为 zsh（注意：不要使用 sudo）\n1chsh -s /bin/zsh\n\n2. 安装 ohmyzsh1sh -c &quot;$(curl -fsSL https://gitee.com/pocmon/ohmyzsh/raw/master/tools/install.sh)&quot;\n\n1sh -c &quot;$(wget -O- https://install.ohmyz.sh/)&quot;\n\n3. 配置主题1git clone --depth=1 https://github.com/romkatv/powerlevel10k.git $&#123;ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom&#125;/themes/powerlevel10k\n\n将 ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot; 添加到 ~/.zshrc 文件中。\n1source ~/.zshrc\n\n4. 配置插件4.1 安装插件\nzsh-autosuggestions 是一个命令提示插件，当你输入命令时，会自动推测你可能需要输入的命令\n\n1git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions\n\n\nzsh-syntax-highlighting 是一个语法高亮插件，当你输入命令时，会高亮显示命令的各个部分\n\n1git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting\n\n\nzsh-completions 是一个补全插件，当你输入命令时，会自动补全命令的各个部分\n\n1git clone https://github.com/zsh-users/zsh-completions $&#123;ZSH_CUSTOM:-$&#123;ZSH:-~/.oh-my-zsh&#125;/custom&#125;/plugins/zsh-completions\n\n\nz 是一个快速切换目录插件，当你输入命令时，会自动切换到你输入的目录\n\n4.2 配置插件将 plugins=(git zsh-autosuggestions zsh-syntax-highlighting zsh-completions z) 添加到 ~/.zshrc 文件中。\n1plugins=(git zsh-autosuggestions zsh-syntax-highlighting zsh-completions z)\n","slug":"linux/Linux安装ohmyzsh","date":"2024-11-25T16:00:00.000Z","categories_index":"Linux","tags_index":"zsh,ohmyzsh","author_index":"Gao"},{"id":"d69aa1e30531a17bb9e8d7f557b88657","title":"ZeroTier内网穿透","content":"使用 ZeroTier 实现内网穿透安装及配置查看其他教程如何实现直连\n主要需要开启 ipv6，开启 ipv6 后可以打洞实现直连，提升连接体验，现在大部分运营商都提供了 ipv6\n使用 zerotier 内网穿透不需要开启 ipv6 公网模式，保证安全又可以实现异地组网\n小米路由开启 ipv6，选择 net 模式就行，不要修改光猫\ntplink 有个 ipv6 桥接模式，开启即可\n\n","slug":"os/zerotier","date":"2024-11-11T06:58:47.000Z","categories_index":"os","tags_index":"内网穿透","author_index":"Gao"},{"id":"9f2df5d79e53f31f7ef018d56fc68fb5","title":"强转溢出与浮点数运算","content":"java 中的数据类型转换.在 java 中，存在两种转换的机制，默认类型转换（隐式转换）和强制类型转换。默认类型转换的规则如下：\n\nbyte，short，char -&gt; int -&gt;long -&gt;float -&gt;double\n\n当 byte，short，char 相互之间不能转换，它们参与运算首先将转换成 int 类型进行运算。\n\n\n强制类型转换：\n\n目标类型 变量名 &#x3D; (目标类型)(被转换的类型)\n\n在进行类型转换时：\n\n容量大的数据类型转换为容量小的数据类型时，要加上强制转换符，但可能造成精度降低或溢出；使用时要格外注意。\n有多种类型的数据混合运算时，系统首先自动的将所有数据转换成容量最大的那一种数据类型，然后再进行计算。\n\nbyte 的存储范围是-128-127 的整数范围，那么如果有如下语句：\n1byte a = (byte)130;\n\n结果会是多少呢？java 是如何处理强制类型转换的溢出处理呢？\n在计算机中，所有的数据都是存储的补码形式，那么 130 首先被当成 int 型存储，四个字节 32 位，它的补码如下：0000 0000 0000 0000 0000 0000 1000 0010，转换为 byte 类型，进行截取，高字节部分去除，保留低字节部分，得到转换为 byte 类型的补码为：1000 0010，我们将其转换为源码：补码（1000 0010）-&gt;反码（1000 0001）-&gt;原码（1111 1110）为-126，所以最后的答案是-126.如果遇到其他的类型转换，也采用类似的处理方法。\n我们都知道 Java 中基本数据类型中，整型的有byte、short、int、long,依次占用内存空间是1、2、4、8个字节，它们的取值范围如下：\n\n\n\n类型\n字节数\n取值范围\n\n\n\nbyte\n1\n[-128，127]\n\n\nshort\n2\n[-32768，32767]\n\n\nint\n4\n[-2147483648，2147483647]\n\n\nlong\n8\n[-9223372036854775808，9223372036854775807]\n\n\n既然数据有范围，那么就会存在数据溢出的问题，那么我们看下数据溢出了会是怎样的？\n原理分析我们知道，整型数据在计算机中都是用二进制表示的。这里我们继续拿 byte 进行举例，比如说1的二进制表示为0000 0001，-1的二进制表示为1000 0001，最高位是符号位，1 表示负数，0 表示正数。\n我们知道byte类型占一个字节，也就是 8bit，那么它应该能表示 128 个数字；除去最高位的符号位后，还有 7 个 bit 来表示数字，也就是[0,127]这个范围，共 128 个数字；如果加上符号位，那么byte可以表示的数的范围是[-127,-0]和[0,127]，-0 和 0 表示的数据相同，我们进行合并，所以范围应该是[-127,127]，而 java 规定的范围是[-128,127]，-128怎么表示的。\n其实-128就是用-0来表示的，二进制的补码表示就是1000 0000。\n接下来我们说下几个基本概念：原码、反码和补码。\n原码、反码和补码原码：就是数据的二进制表示形式，最高位是符号位，1 表示负数，0 表示正数。\n反码：正数的反码跟原码相同；负数的反码是在原码的基础上，符号位不变，其余各位取反，1 变 0，0 变 1。\n补码：正数的补码跟原码相同；负数的补码是在其反码的基础上加 1。\n比如说，10的原码是0000 1010，由于它是正数，所以它的反码和补码均与原码相同。 -10的原码是1000 1010；它的反码是在原码基础上，符号位不变，其余位数取反，转换后的反码是1111 0101；补码是在反码的基础上+1，转换后的补码是1111 0110。\n加法运算过程拆解在计算机的二进制计算中，减法运算也会转化为加法运算来计算。\n对于10-10=0的这个运算，在实际计算过程中，会将10 - 10的操作转化为10 + (-10)。接下来我们看下具体的运算过程：\n\n\n\n数据类型\n10\n-10\n\n\n\n原码\n0000 1010\n1000 1010\n\n\n反码\n0000 1010\n1111 0101\n\n\n补码\n0000 1010\n1111 0110\n\n\n得到对应的补码之后，我们对10和-10的补码进行加法操作：\n1234+ 0000 1010——————————— = 0000 0000  1111 0110复制代码\n\n我们知道补码0000 0000对应的原码也为0000 0000，所以可以得出10 - 10 = 0。\n验证(byte)(127 +1)结果我们接着看下byte类型的127 + 1的运算过程。\n\n\n\n数据类型\n127\n1\n\n\n\n原码\n0111 1111\n0000 0001\n\n\n反码\n0111 1111\n0000 0001\n\n\n补码\n0111 1111\n0000 0001\n\n\n得到对应的补码之后，我们对相应的补码进行加法操作：\n1234+ 0111 1111——————————— = 1000 0000  0000 0001复制代码\n\n这里我们得到了1000 0000这个补码，而这个补码对应的数据就是-128，这是一个特例。\n这里需要注意的是，因为使用以前的-0的补码来表示-128, 所以-128并没有原码和反码表示。(对-128 的补码表示[1000 0000]补算出来的原码是[0000 0000], 这是不正确的)。\n浮点数运算和整数运算相比，只能进行加减乘除这些数值计算，不能做位运算和移位运算。\n在计算机中，浮点数虽然表示的范围大，但是，浮点数有个非常重要的特点，就是浮点数常常无法精确表示。\n举个栗子：\n浮点数0.1在计算机中就无法精确表示，因为十进制的0.1换算成二进制是一个无限循环小数，很显然，无论使用float还是double，都只能存储一个0.1的近似值。但是，0.5这个浮点数又可以精确地表示。\n因为浮点数常常无法精确表示，因此，浮点数运算会产生误差：\n电脑是怎样储存一个整数的(Integer)在讲为什么会存在浮点误差之前，先来谈谈电脑是怎么用 0 跟 1 来表示一个 整数 的，大家应该都知道二进制：例如 101 代表 $2^2 + 2^0$ 也就是 5、1010 代表 $2^3 + 2^1$ 也就是 10。\n\n如果是一个无符号的 32 bit 整数，代表它有 32 个位置可以放 0 或 1，所以最小值就是 0000...0000 也就是 0，而最大值 1111...1111 代表 $2^{31} + 2^{30} + … + 2^1 + 2^0$ 也就是 4294967295\n从排列组合的角度来看，因为每一个 bit 位都可以是 0 或 1，整个变量的值有 $2^{32}$ 种可能，所以可以 精确的 表达出 0 到 $2^{23} - 1$ 之间的任一个值，不会有任何误差。\n浮点数(Floating Point)虽然从 0 到 $2^{23} - 1$ 之间存在很多个整数，但其数量终究是 有限 的，就是 $2^{32}$ 那么多个而已；但浮点数就不同了，我们可以这样想：在 1 到 10 这个区间中只有十个整数，却有 无穷多个 浮点数，例如 5.1、5.11、5.111 等等，怎么也列举不完。\n但因为在 32 bit 的空间中就只有 2³² 种可能性，为了把所有浮点数都塞在这个 32 bit 的空间里面，许多 CPU 厂商发明了各种浮点数的表示方式，但如果每家 CPU 的格式都不一样也很麻烦，所以最后是以 IEEE 发布的 IEEE 754 作为通用的浮点数运算标准，现在的 CPU 也都遵循这个标准进行设计。\nIEEE 754IEEE 754 里面定义了很多东西，其中包括单精度（32 bit）、双精度（64 bit）和特殊值（无穷大、NaN）的表示方式等等\n规格化以 8.5 这个浮点数来说，如果要变成 IEEE 754 格式的话必须先做一些规格化处理：把 8.5 拆成 8 + 0.5 也就是 $2^3 + (\\cfrac{1}{2})^1$ ，接着写成二进位变成 1000.1，最后再写成 $1.0001 \\times 2^3$，与十进制的科学记数法很相似。\n单精度浮点数在 IEEE 754 中 32 bit 浮点数被拆分成三个部分，分别是 数符（sign）、阶码（exponent） 和尾数（fraction），加起来总共是 32 个 bit\n\n\n数符（sign）：最左侧的 1 bit 代表正负号，正数的话 sign 就为 0，反之则是 1\n阶码（exponent）：中间的 8 bit 代表规格化之后的次方数，采用的是 阶码真值 +127 的格式，也就是 3 还要再加上 127 等于 130\n尾数（fraction）：最右侧的 23 bit 放的是小数部分，以 1.0001 来说就是去掉 1. 之后的 0001\n\n所以如果把 8.5 表示成 32 bit 格式的话应该是这样：\n\n什么情况下会产生误差？前面举的 8.5 的例子可以表示为 $2^3 + (\\cfrac{1}{2})^1$ ，是因为 8 和 0.5 刚好都是 2 的次方数，所以完全不会产生任何精准度问题。\n但如果是 8.9 的话因为没办法换成 2 的次方数相加，所以最后会被迫表示成 $1.0001110011… \\times 2^3$，而且还会产生大概 $0.0000003$ 的误差，如果对结果好奇的话可以到 IEEE-754 Floating Point Converter 网站上玩玩看。\n双精度浮点数前面所讲的单精度浮点数只用了 32 bit 来表示，为了让误差更小，IEEE 754 也定义了如何用 64 bit 来表示浮点数，跟 32 bit 比起来 fraction 部分扩大了两倍多，从 23 bit 变成 52 bit，所以精准度自然会提高许多。\n\n以刚才的 8.9 为例，用 64 bit 表示的话虽然可以变得更准，但因为 8.9 无法完全写成 2 的次方数相加，到了小数下 16 位仍然会出现误差，不过与单精度的误差 0.0000003 比起来已经小了很多\n\n类似的情况还有像 Python 中的 1.0 跟 0.999...999 是相等的、123 跟 122.999...999 也是相等的，因为他们之间的差距已经小到无法放在 fraction 里面，所以从二进制格式看来它们每一个二进制位都是一样的。\n\n解决方法既然浮点数的误差是无法避免的，那就只好跟它共处了，下面是两个比较常见的处理方法：\n设定最大允许误差 ε (epsilon)在某些语言会提供所谓的 epsilon，用来让你判断是不是在浮点误差的允许范围内，以 Python 来说 epsilon 的值大约是 $2.2e^{-16}$\n\n所以你可以把 0.1 + 0.2 == 0.3 改写成 0.1 + 0.2 — 0.3 &lt;= epsilon，这样就能避免浮点误差在运算过程中捣乱，正确的比较出 0.1 加 0.2 是不是等于 0.3 了。\n\n当然如果系统没提供的话你也可以自己定义一个 epsilon，设定在 2 的 -15 次方左右\n\n完全使用十进制进行计算之所以会有浮点误差，是因为把十进制转为二进制的过程中没办法把所有的小数部分都塞进了尾数中，既然转换可能会有误差，那干脆就不转了，直接用十进制来做运算。\n在 Python 里面有一个 module 叫做 decimal，在 JavaScript 中也有类似的包。它可以帮你用十进制来进行计算，就像你自己用纸笔计算 0.1 + 0.2 绝对不会出错、也不会有任何误差。\n\n虽然用十进制进行计算可以完全避免浮点数的误差，但因为 Decimal 的十进制计算是模拟出来的，在最底层的 CPU 电路中还是在用二进制进行运算，执行起来会比原生的浮点运算慢很多，所以不建议所有的浮点运算都用 Decimal 来进行。\n","slug":"强转溢出与浮点数运算","date":"2021-10-08T17:04:46.000Z","categories_index":"Java","tags_index":"Java","author_index":"Gao"},{"id":"bc1fb47b9cf98affb24c2221bfc0ad99","title":"黑苹果优化","content":"黑果优化\n命令调试检查\n\n12345678# 检查 XCPM 是否正常加载，返回 1为正常$ sysctl machdep.xcpm.mode# 验证 X86PlatformPlugin.kext 是否已经加载$ kextstat|grep -y x86plat# 验证 Apple Intel CPU 电源管理，返回为空表示正常$ kextstat|grep -y appleintelcpu# 验证是否加载变频，返回 1 为正常$ sysctl -n machdep.xcpm.vectors_loaded_count\n\n\nMac 升级后配置上的小红点去掉方法\n\n123# 在终端执行下面命令：$ defaults write com.apple.systempreferences AttentionPrefBundleIDs 0$ killall Dock\n\n\n禁止系统更新提示代码命令\n\n123$ sudo softwareupdate --ignore “macOS Catalina”# 放弃更改，使用下面进行重置$ sudo softwareupdate --reset-ignored\n\n\n安装任何来源软件\n\n12345$ sudo spctl --master-disable# 可选：关闭sip，即System Integrity Protection系统完整保护，将一些文件目录和系统应用保护了起来$ csrutil disable# 查看关闭状态csrutil status\n\n\n本 Mac 和 Win 系统的时间不同步问题及解决方法：\n\n12# win系统里，请在管理员cmd运行命令如下：Reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1\n\n\n安装 Mac os 后“其他宗卷”占用大量空间，这个问题通常是 Mac 的“safe sleep”功能开启导致的，关闭方法如下：\n\n123# 在终端中输入下面的命令$ sudo pmset -a hibernatemode 0# 然后定位到/private/var/vm/删除已经存在的sleepimage文件\n\n\n升级 10.15 后，开启 hidpi 用之前的脚本方式无法开启，新系统 system&#x2F;library 变成了只读，脚本文件无法写入，解锁方式：\n\n12$ sudo mount -uw /$ killall Finder\n\n\nKext Utility 了解，由于 macOS 10.15 锁住了 S&#x2F;L&#x2F;E 的修改权限，因此在修改 kext 前要使用终端先解锁 System&#x2F;Library&#x2F;Extensions 权限\n\n123456# 打开终端依次输入$ sudo su$ sudo mount -uw /$ killall Finder# 重建缓存sudo touch /System/Library/Extensions &amp;&amp; sudo kextcache -u\n","slug":"hackintosh/黑苹果优化","date":"2021-08-30T21:35:55.000Z","categories_index":"hackintosh","tags_index":"hackintosh","author_index":"Gao"},{"id":"05c02e8953cff3fb4287b628204907a3","title":"HTML元素间距问题","content":"HTML 元素间距问题在利用 CSS 布局时，经常会遇到一些没有定义间距 padding、margin 之类的内容，但是页面上却总会有一些不知从何而来的间距出现，下面就是我在自己的工作中遇到的一些常见情况的总结，及其消除方法。\n\n并排 div 之间的间距。a. 多个 div 元素在定义属性：display:inline-block;后，多个 div 元素之间并排排列，但是它们之间总是隔着那么几像素的距离，即便你一次又一次修改自己的 padding、margin 设置为 0，都没办法取消。\nb. 它们之间存在的间距，是因为不同 div 之间存在默认间距，因为写代码的习惯，一个 div 元素结束之后，我们总会换行开始写代码，这一换行就是 div 之间存在间距的原因。\n所以解决办法很简单，a.去掉代码上不同 div 元素之间的换行或者空格即可，这个方法在代码可读性上有些不可取。如果你对代码格式有很严格的限制，像我一样是个无可救药的强迫症，你就选择下面的方法吧。b.利用注释将 div 之间的空格标记起来。c.网上还有人提到过一种解决方案，将 margin 设置为负值，这个方法也是可行的，但是由于浏览器之间的标准差异，margin 的设置可能会需要在不同浏览器中设置为不同的值，增加了工作的复杂度。\n123456789&lt;div class=&quot;color-choice&quot;&gt;        &lt;p&gt;this is div 1.&lt;/p&gt;     &lt;/div&gt;&lt;!--     --&gt;&lt;divclass=&quot;color-choice&quot;&gt;       &lt;p&gt;this is div 1.&lt;/p&gt;     &lt;/div&gt;&lt;!--     --&gt;&lt;divclass=&quot;color-choice&quot;&gt;      &lt;p&gt;this is div 1.&lt;/p&gt;     &lt;/div&gt;\n\n","slug":"html/HTML元素间距问题","date":"2021-08-10T18:49:46.000Z","categories_index":"问题归纳","tags_index":"html","author_index":"Gao"},{"id":"bc29b33099bfdf6d7fd5667c80c7230d","title":"Linux添加Service","content":"Linux 添加 Service 实现自启动\n以启动 jar 包为例\n\n\ncd &#x2F;ets&#x2F;systemd&#x2F;system\n创建自己的 service 文件\n\n\n12345678910111213141516[Unit]Description=yourProjectName #描述After=syslog.target network.target #依赖[Service]Type=simpleExecStart=/usr/bin/java -jar /opt/javaapps/yourProjectName.jar#前面是java命令的绝对路径 后面是jar包的绝对路径ExecStop=/bin/kill -15 $MAINPIDUser=rootGroup=root[Install]WantedBy=multi-user.target\n","slug":"linux/Linux添加Service","date":"2021-05-10T00:16:16.000Z","categories_index":"Linux","tags_index":"","author_index":"Gao"},{"id":"50317e389506882f376cd4700774fd2f","title":"Linux安装docker","content":"Centos 安装最新稳定版 docker 方法\n脚本安装\n\n12curl -fsSL get.docker.com -o get-docker.shsh get-docker.sh --mirror Aliyun\n","slug":"linux/Linux安装docker","date":"2021-04-20T21:10:39.000Z","categories_index":"Linux","tags_index":"docker","author_index":"Gao"},{"id":"7a05e9f0505455fe4ba151c28ae4d236","title":"Spring整合WebSocket","content":"Spring 整合 websocket 设置\nMaven 添加 Jar 包\n\n123456789101112&lt;!-- spring websocket --&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework&lt;/groupId&gt;\t&lt;artifactId&gt;spring-websocket&lt;/artifactId&gt;\t&lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework&lt;/groupId&gt;\t&lt;artifactId&gt;spring-messaging&lt;/artifactId&gt;\t&lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- websocket end --&gt;\n\n\nSpring xml 配置方式\n\n12345678910111213&lt;!-- websocket 配置 --&gt;&lt;websocket:message-broker application-destination-prefix=&quot;/app&quot;&gt;&lt;websocket:stomp-endpoint path=&quot;/websocket&quot;&gt;\t\t&lt;websocket:sockjs /&gt;\t&lt;/websocket:stomp-endpoint&gt;\t&lt;websocket:simple-broker prefix=&quot;/topic&quot;/&gt;\t&lt;websocket:client-inbound-channel&gt;\t\t&lt;websocket:interceptors&gt;\t\t&lt;bean class=&quot;net.example.projects.web.WebSocketInterceptor&quot;/&gt;\t\t&lt;/websocket:interceptors&gt;\t&lt;/websocket:client-inbound-channel&gt;&lt;/websocket:message-broker&gt;&lt;!-- websocket end --&gt;\n\n此处启用 stomp\nSTOMP 中文为: 面向消息的简单文本协议\nwebsocket定义了两种传输信息类型:文本信息和二进制信息。类型虽然被确定，但是他们的传输体是没有规定的。所以，需要用一种简单的文本传输类型来规定传输内容，它可以作为通讯中的文本传输协议。\nSTOMP 是基于帧的协议，客户端和服务器使用 STOMP 帧流通讯\n一个 STOMP 客户端是一个可以以两种模式运行的用户代理，可能是同时运行两种模式。\n\n作为生产者，通过SEND框架将消息发送给服务器的某个服务\n作为消费者，通过SUBSCRIBE制定一个目标服务，通过MESSAGE框架，从服务器接收消息。\n\n基于 websocket 的一层 STOMP 封装，让业务端只需关心数据本身，不需要太过关心文本协议。当然还是需要了解一些 STOMP 协议各个 Frame 的概念和应用场景。\n\n拦截器配置\n\n12345678910111213141516171819202122public class WebSocketInterceptor extends ChannelInterceptorAdapter &#123;    @Override    public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) &#123;        StompHeaderAccessor accessor = MessageHeaderAccessor.getAccessor(message, StompHeaderAccessor.class);        //1、判断是否首次连接        if (StompCommand.CONNECT.equals(accessor.getCommand())) &#123;            String userId = accessor.getNativeHeader(&quot;userId&quot;).get(0);            String name = userId;            Principal principal = () -&gt; name;            WebSocketManager.connect(name);            accessor.setUser(principal);            return message;        &#125; else if (StompCommand.DISCONNECT.equals(accessor.getCommand())) &#123;            Principal principal = accessor.getUser();            WebSocketManager.disconnect(principal.getName());        &#125; else &#123;        &#125;        return message;    &#125;&#125;\n\n拦截处理连接和断开操作，Principal 设置连接的用户，之后就可以发送消息到指定用户。\n常用 Command\nCONNECT\nCONNECTED\nSEND\nSUBSRIBE\nUNSUBSRIBE\nBEGIN\nCOMMIT\nABORT\nACK\nNACK\nDISCONNECT\n\n消息服务器可以通过@MessageMapping方法处理请求\nSendToUser(&quot;/topic/websocket&quot;)发送消息\n需要强调的是 web.xml 中的路径匹配问题 写为&#x2F;全部匹配的\n如果使用路径匹配&#x2F;wsk&#x2F;*\nspring 中的地址不能写为&lt;websocket:mapping path&#x3D;”&#x2F;wsk&#x2F;echo” 只需要写为 &lt;websocket:mapping path&#x3D;”&#x2F;echo”就可以了,不然无法访问,这个是很多人都会遇到的坑.需特别注意\n手动管理 WebSocketSession配置时添加\n12345&lt;websocket:transport&gt;\t\t\t&lt;websocket:decorator-factories&gt;\t\t\t\t&lt;bean class=&quot;net.example.web.CustomWebSocketHandlerDecorator&quot;/&gt;\t\t\t&lt;/websocket:decorator-factories&gt;&lt;/websocket:transport&gt;\n\n添加代码\n\n将 WebSocketSession 保存，留作后续处理\n","slug":"java/Spring整合WebSocket","date":"2021-03-26T22:22:51.000Z","categories_index":"Java","tags_index":"Spring","author_index":"Gao"},{"id":"d2eee44587e5bd7c8d2511537bf5b990","title":"Somenote","content":"1. Java 中 new Date(long date)如果是 10 位时间戳,就是秒级别的转成 date 是有问题的,成格林尼治时间需要用毫秒级的,就是 13 的时间戳才能得到正确的时间\n2. html 中的 disable\nhtml 中的标签添加 disable 属性后不会将属性发送到后台,readonly 可以,但是 select 标签是没有 readonly 属性,所以需要用其他方法解决.\n\n","slug":"java/somenote","date":"2021-02-18T18:28:35.000Z","categories_index":"记录","tags_index":"随笔","author_index":"Gao"},{"id":"b6a9caeeb7241bffd17076a1e5fbb45c","title":"Resume","content":"","slug":"resume","date":"2020-07-27T22:23:31.000Z","categories_index":"resume","tags_index":"resume","author_index":"Gao"},{"id":"1856d3fe3ee680c79f813e9ac26f130d","title":"深入理解 JVM 之 垃圾回收机制","content":"转自 https://juejin.im/post/5c73c7c96fb9a049dd80eedb\n深入理解 JVM 之 垃圾回收机制虽然内存的分配和回收技术已相当成熟，但如果需要排查内存溢出、内存泄露问题，或者要求高并发、高性能时，就需要对垃圾的回收进行监控和调节，以更好优化系统提高性能。\n对象存活判定Java 内存结构中，程序计数器、虚拟机栈、本地方法栈等随着线程而生，随线程而灭，不需要考虑内存回收问题。而 Java 堆和方法区则不同，它们的内存分配是动态的，只有在运行期间才能知道会创建哪些对象，垃圾回收关注的就是这两部分。\n垃圾回收首先需要判断哪些对象还存活着，主要有引用计数和可达性分析两种算法。\n引用计数算法它的原理如下：给对象添加一个引用计数器，每当有一个地方引用它时，计时器值就加 1；当引用失效时，计数器值就减 1；如果计数器为 0，对象就不可能再被使用。\n引用计数算法虽然实现简单、判定效率较高。但它很难解决对象之间循环引用的问题。\n例如两个对象相互引用，实际上两个对象都不会再访问，但因为相互引用着对方，导致它们的计数器值都不为 0，于是引用技术算法无法通过 GC 收集器回收它们。\n可达性分析算法它的原理如下：通过一系列称为 GC Roots 的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明对象是不可用的。\nJava 中，可作为 GC Roots 的对象包括如下几种：\n\n虚拟机栈（栈帧中的本地变量表）中引用的对象；\n方法区中类静态属性引用的对象；\n方法区中常量引用的对象；\n本地方法栈中 JNI( Native 方法) 引用的对象。\n\n引用类型可以看到，对象回收判定算法判断对象是否存活都与引用有关。从 JDK1.2 开始，引用分为四种类型，用来实现不同的功能，它们的引用强度也依次递减。\n强引用（Strong Reference）\n平时使用的引用就是强引用。只要强引用还存在，该对象永远不会被回收。\n可以通过将对象设置为 null，使其被回收。\n软引用（Soft Reference）\n用于描述一些还有用但并非必需的对象。当系统内存空间不足时，会回收这些软引用指向的对象。它通过 SoftReference 类来实现软引用。\n可以用来实现高速缓存。\n弱引用（Weak Reference）\n用来描绘非必需对象。被弱引用指向的对象只能生存到下一次垃圾回收之前。只要垃圾收集器运行，弱引用指向的对象就会被回收。它通过 WeakReference 类来实现弱引用。\n虚引用（Phantom Reference）\n虚引用和没有引用没有任何区别。一个对象是否有虚引用，不会影响其生存时间，也无法通过虚引用获取对象实例。它通过 PhantomReference 来实现虚引用。必须和引用队列 ReferenceQueue 联合使用。\n为一个对象设置虚引用的唯一目的是该对象被垃圾收集器回收前会收到一条系统通知。\n回收方法区方法区，或者说 HotSpot 虚拟机中的永久代，进行垃圾回收的效率一般比较低。回收主要包括两部分内容：废弃常量和无用的类。\n判断一个常量是否是废弃常量比较简单，与回收 Java 堆中的对象类似。而判定一个类是否是无用的类需要满足三个条件：\n\n该类所有的实例都已经被回收；\n加载该类的 ClassLoader 已经被回收；\n该类对象的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n垃圾收集算法标记-清除算法（Mark-Sweep）标记-清除算法分为两个标记和清除阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。标记过程也就是对象存活判定算法。\n\n它是最基础的收集算法，主要有两个缺点：\n\n效率问题：标记和清除两个过程的效率都不高。\n空间问题：标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大的对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。\n\n复制算法（Copying）复制算法将可用内存分为大小相等的两块，每次只使用其中的一块。在一块内存用完后，将仍存活的对象赋值到另一块上面，再把已使用过的内存一次清理掉。\n\n复制算法的优缺点如下：\n\n优点：每次对半个分区进行内存回收，内存分配时也不用考虑内存碎片等情况，实现简单，运行高效。\n缺点：可使用的内存缩小为一半，代价较大。\n\n标记-整理算法（Mark-compact）标记-整理算法分为标记和整理两个阶段，标记阶段和“标记-清除算法”一样，但在整理阶段，不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n\n标记-整理算法的优缺点如下：\n\n避免了空间碎片，空间利用率较高。\n效率不高，标记和清除过程的效率较低。\n\n分代算法（Generational Collection）分代算法根据对象存活周期将内存划分为几块。一般是将 Java 对分为新生代和老年代，根据各个年代的特点采用适当的收集算法。\n新生代中，每次垃圾收集时只有少量对象存活，选择复制算法；老年代中，对象存活率较高、没有额外空间进行分配，使用“标记-清理”或“标记-整理”算法。\n为了对不同生命周期的对象采用不同的回收算法，所以垃圾收集器都采用分代收集算法，将堆分为新生代和老年代。\n\n内存分配和回收策略新生代新生代主要用来存放新创建的对象，一般占堆 1/3 的空间。由于很多对象生命周期很短，每次 Minor GC 后只有少量对象存活，所以选用复制算法。\n新生代又被分为一块较大的 Eden 区和两块较小的大小相等的 Survivor 区，使用 from 和 to来分别指代两个 Survivor 区。HotSpot 虚拟机默认 Eden 和两块 Survivor 的大小比例为 8:1:1。每次只会使用 Eden 和其中一块 Survivor 区为对象服务，所以总是有一块 Survivor区是空闲的，新生代实际可用的内存空间也就为 90%。\n通常，对象会分配在 Eden 区中，当 Eden 区无法在分配对象时，JVM 便会触发一次 Minor GC，将存活下来的对象复制到 from 指向的 Survivor 区中。\n当 from 指向的 Survivor 区也无法分配时，对 Eden 和 from 指向的 Survivor 区执行 Minor GC，将存活下来的对象复制到 to 指向的 Survivor 区中，然后交换 from 和 to 指针，使 to指向的 Survivor 区为空，以保证下次 Minor GC 有复制的空闲空间。\n老年代老年代用于存放大对象，或年龄超过一定程度的对象。一般占据堆 2/3 的空间。\n如果对象需要大量连续的内存空间，例如很长的字符串及数组，这些对象会直接分配在老年代，以避免在 Eden 区及两个 Survivor 区之间发生大量的内存复制。\n虚拟机为每个对象定义了一个对象年龄计数器，如果对象分配在 Eden 区，在经过一次 Minor GC后仍然存活，之后移动到 Survivor 空间中，将其年龄设置为 1。对象在 Survivor 区中每经过一次 Minor GC，年龄就增加一次，当它的年龄增加到一定程度（默认为 15）时，也会被晋升到老年代中。\n如果在 Survivor 区中相同年龄所有对象大小的总和大于 Survivor 区的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。\n老年代的对象一般都比较稳定，Major GC 不会频繁执行。Major GC 采用标记—清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没有标记的对象。MajorGC 的耗时较长，而且会产生内存碎片。\n三种清理方式Minor GC(Young GC)\n指发生在新生代的垃圾收集动作。当 Eden 区没有足够的空间分配时，就会触发一次 Minor GC。由于 Java 对象大多生命周期较短，所以 Minor GC 非常频繁，一般回收速度也比较快。\nMajor GC\n指发生在老年代的垃圾收集动作，在进行 Major GC 前，一般都会进行至少一次 Minor GC。Major GC 的速度一般会比 Minor GC 慢 10 倍以上。\nFull GC\n指回收整个新生代和老年代的垃圾收集动作。成本较高，对系统性能产生影响。FULL GC 的时候会 STOP THE WORD。\n它的触发条件主要有：\n\n在执行 Minor GC 之前，如果老年代最大可用的连续空间小于历次晋升到老生代对象的平均大小，则触发一次 Full GC 。\n大对象直接进入老年代，或从年轻代晋升上来的老对象，在老年代尝试分配内存，但老年代内存空间不够时。\n显式调用 System.gc() 方法时。\n\n","slug":"java/深入理解-JVM-之-垃圾回收机制","date":"2020-04-27T21:28:19.000Z","categories_index":"java","tags_index":"jvm","author_index":"Gao"},{"id":"5e487e249d6b6207e7d21f7db089653a","title":"Wsl","content":"创建启动脚本\n进入任意 WSL 发行版本中,创建并编辑文件: &#x2F;etc&#x2F;init.wsl\n\n1234#! /bin/sh/etc/init.d/cron $1/etc/init.d/ssh $1/etc/init.d/supervisor $1\n\n里面调用我们希望启动的 3 个服务启动脚本,设置权限,所有者为 root,然后通过\n\nsudo &#x2F;etc&#x2F;init.wsl [start|stop|restart]\n\n来启动我们的服务,在 Windows 中,开始-运行输入:\n\nshell:startup\n\n按照 WSL 使用的 Linux 发行版本启动脚本,如 Ubuntu18.04,创建 ubuntu18.04.vbs:\n12Set ws = CreateObject(&quot;Wscript.Shell&quot;)ws.run &quot;wsl -d Ubuntu-18.04 -u root /etc/init.wsl start&quot;, vbhide\n\n如果不知道什么版本可以用 wsl -l 来查看.\nWSL 中有很多其他服务,按需修改&#x2F;etc&#x2F;init.wsl 就可以了.\n","slug":"os/wsl","date":"2020-04-27T21:27:34.000Z","categories_index":"os","tags_index":"wsl","author_index":"Gao"},{"id":"e3f21e9acef3198d027ae212013ef3d8","title":"Windows Scoop","content":"官网https://scoop.sh\n安装\n自定义 scoop 包安装路径运行下方三行代码\n\n\n\n$env:SCOOP&#x3D;’F:\\scoop’\n\n\n\n“[environment]::setEnvironmentVariable(‘SCOOP’,$env:SCOOP,’User’)”\n\n\n\niex (new-object net.webclient).downloadstring(‘https://get.scoop.sh‘)\n\n\n\n常用软件列表\n7zip：scoop install 7zip\naria2 引擎：scoop install aria2\nchrome：scoop install chrome\nfirefox：scoop install firefox\nopera：scoop install opera\nvivaldi：scoop install vivaldi\ngit：scoop install git\npython：scoop install python\nvscode：scoop install vscode\nsublime-text：scoop install sublime-text\nnotepadplusplus：scoop install notepadplusplus\ntelegram：scoop install telegram\ntypora：scoop install typora\n\nBucket 软件源由于 scoop 比较小众，软件相比 chocolatey 较少不过 scoop 有一个强大的 bucket 软件源策略，而且有社区来维护常用软件基本能够找到\n社区地址：https://github.com/rasa/scoop-directory/blob/master/by-score.mdbucket 语法：scoop bucket add [软件源名字(随意)] [源地址]\nbucket 源推荐：\n官方：scoop bucket add mainscoop bucket add extrasscoop bucket add versionsscoop bucket add nightliesscoop bucket add nirsoftscoop bucket add phpscoop bucket add nerd-fontsscoop bucket add nonportablescoop bucket add javascoop bucket add gamesscoop bucket add jetbrains\n国内常用软件：微信、QQ、钉钉……scoop bucket add dorado https://github.com/h404bi/dorado\n小新 Bucket：FSCapture、Shadowsocksrr、UninstallTool、Notepad3、Wechat……scoop bucket add dajiu https://github.com/dajiiu/dajiu-scoop\n其他：scoop bucket add dodorz https://github.com/dodorz/scoop-bucket\n遇到的问题\n在安装过程中如果意外终止是没办法继续安装的需要 uninstall 一下然后才能重新安装\n\n","slug":"os/windows-scoop","date":"2020-04-27T21:26:31.000Z","categories_index":"os","tags_index":"scoop","author_index":"Gao"},{"id":"0a640b43ba2e6fd4cef7f6c9ce1c6f16","title":"Unity全面屏适配 IOS","content":"Unity 全面屏适配\n修改 xcode 方法\n\n123456789101112131415string src = @&quot;    _window         = [[UIWindow alloc] initWithFrame: [UIScreen mainScreen].bounds];&quot;;string dst = @&quot;//    _window         = [[UIWindow alloc] initWithFrame: [UIScreen mainScreen].bounds];  CGRect winSize = [UIScreen mainScreen].bounds;  if (winSize.size.width / winSize.size.height &gt; 2) &#123;      winSize.size.width -= 64;      winSize.origin.x = 32;  &#125;  _window = [[UIWindow alloc] initWithFrame: winSize];  &quot;;       string unityAppControllerPath = path + &quot;/Classes/UnityAppController.mm&quot;;       XClassExt UnityAppController = new XClassExt (unityAppControllerPath);       UnityAppController.Replace (src, dst);\n\n\n修改 UGUI 方法\n\n","slug":"unity3d/Unity全面屏适配-IOS","date":"2020-04-27T21:24:45.000Z","categories_index":"unity3d","tags_index":"ugui","author_index":"Gao"},{"id":"4ad643c3b688b2b0038ebbf29d874ce0","title":"Java面试题收集整理","content":"Java 相关知识点ArrayList 和 Vector 的区别\n这张图里的内容对我们学习 Java 来说，非常的重要，白色的部分是需要去了解的，黄色部分是我们要去重点了解的，不但要知道怎么去用，至少还需要读一次源码。绿色部分内容已经很少用了，但在面试题中有可能会问到，我们来看一个经常出现的面试题：ArrayList 与 Vector 的区别是什么？\n**首先我们给出标准答案： **\n**1、Vector 是线程安全的，ArrayList 不是线程安全的。 **\n2、ArrayList 在底层数组不够用时在原来的基础上扩展 0.5 倍，Vector 是扩展 1 倍。\n看上图 Vector 和 ArrayList 一样，都继承自 List，来看一下 Vector 的源码\n123456789101112131415public class Vector&lt;E&gt;    extends AbstractList&lt;E&gt;    implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123;    /**     * The array buffer into which the components of the vector are     * stored. The capacity of the vector is the length of this array buffer,     * and is at least large enough to contain all the vector&#x27;s elements.     *     * &lt;p&gt;Any array elements following the last element in the Vector are null.     *     * @serial     */    protected Object[] elementData;\n\n实现了 List 接口，底层和 ArrayList 一样，都是数组来实现的。分别看一下这两个类的 add 方法，首先来看 ArrayList 的 add 源码\n1234567891011/**     * Appends the specified element to the end of this list.     *     * @param e element to be appended to this list     * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;)     */    public boolean add(E e) &#123;        ensureCapacityInternal(size + 1);  // Increments modCount!!检查是否需要扩容        elementData[size++] = e; //给元素赋值        return true;    &#125;\n\n再看 Vector 的 add 源码\n12345678910111213/**     * Appends the specified element to the end of this Vector.     *     * @param e element to be appended to this Vector     * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;)     * @since 1.2     */    public synchronized boolean add(E e) &#123; //加了一个synchronized关键字        modCount++;        ensureCapacityHelper(elementCount + 1); //检查是否需要扩容        elementData[elementCount++] = e; //给元素赋值        return true;    &#125;\n\n方法实现都一样，就是加了一个 synchronized 的关键字，remove 方法也是一样。\n只要是关键性的操作，方法前面都加了 synchronized 关键字，来保证线程的安全性。当执行 synchronized 修饰的方法前，系统会对该方法加一把锁，方法执行完成后释放锁，加锁和释放锁的这个过程，在系统中是有开销的，因此，在单线程的环境中，Vector 效率要差很多。（多线程环境不允许用 ArrayList，需要做处理）。\n和 ArrayList 和 Vector 一样，同样的类似关系的类还有 HashMap 和 HashTable，StringBuilder 和 StringBuffer，后者是前者线程安全版本的实现。\nHashMap 原理及实现学习总结一. HashMap 的工作原理HashMap 基于 hashing 原理，我们通过 put()和 get()方法储存和获取对象。当我们将键值对传递给 put()方法时，它调用键对象的 hashCode()方法来计算 hashcode，让后找到 bucket 位置来储存值对象。当获取对象时，通过键对象的 equals()方法找到正确的键值对，然后返回值对象。HashMap 使用 LinkedList 来解决碰撞问题，当发生碰撞了，对象将会储存在 LinkedList 的下一个节点中。 HashMap 在每个 LinkedList 节点中储存键值对对象。当两个不同的键对象的 hashcode 相同时会发生什么？ 它们会储存在同一个 bucket 位置的 LinkedList 中。键对象的 equals()方法用来找到键值对。\n二.HashMap 的定义HashMap 实现了 Map 接口，继承 AbstractMap。其中 Map 接口定义了键映射到值的规则，而 AbstractMap 类提供 Map 接口的骨干实现，以最大限度地减少实现此接口所需的工作！\n123public class HashMap&lt;K,V&gt;    extends AbstractMap&lt;K,V&gt;    implements Map&lt;K,V&gt;, Cloneable, Serializable\n\n三.HashMap 的数据结构HashMap 的底层主要是基于数组和链表来实现的，它之所以有相当快的查询速度主要是因为它是通过计算散列码来决定存储的位置。HashMap 中主要是通过 key 的 hashCode 来计算 hash 值的，只要 hashCode 相同，计算出来的 hash 值就一样。如果存储的对象对多了，就有可能不同的对象所算出来的 hash 值是相同的，这就出现了所谓的 hash 冲突。学过数据结构的同学都知道，解决 hash 冲突的方法有很多，HashMap 底层是通过链表来解决 hash 冲突的。\n\n紫色部分即代表哈希表，也称为哈希数组，数组的每个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的 key 映射到了数组的同一位置处，就将其放入单链表中。\n四.HashMap 的构造函数在这里提到了两个参数：初始容量，加载因子。这两个参数是影响 HashMap 性能的重要参数，其中容量表示哈希表中桶的数量，初始容量是创建哈希表时的容量，加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度，它衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是 O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为 0.75，一般情况下我们是无需修改的。当哈希表中的条目数超出了加载因子与当前容量的乘积时，通过调用 rehash 方法将容量翻倍。\n五.HashMap 的存储实现HashMap 中我们最长用的就是 put(K, V)和 get(K)。我们都知道，HashMap 的 K 值是唯一的，那如何保证唯一性呢？我们首先想到的是用 equals 比较，没错，这样可以实现，但随着内部元素的增多，put 和 get 的效率将越来越低，这里的时间复杂度是 O(n)，假如有 1000 个元素，put 时需要比较 1000 次。实际上，HashMap 很少会用到 equals 方法，因为其内通过一个哈希表管理所有元素，哈希是通过 hash 单词音译过来的，也可以称为散列表，哈希算法可以快速的存取元素，当我们调用 put 存值时，HashMap 首先会调用 K 的 hashCode 方法，获取哈希码，通过哈希码快速找到某个存放位置，这个位置可以被称之为 bucketIndex，通过上面所述 hashCode 的协定可以知道，如果 hashCode 不同，equals 一定为 false，如果 hashCode 相同，equals 不一定为 true。所以理论上，hashCode 可能存在冲突的情况，有个专业名词叫碰撞，当碰撞发生时，计算出的 bucketIndex 也是相同的，这时会取到 bucketIndex 位置已存储的元素，最终通过 equals 来比较，equals 方法就是哈希码碰撞时才会执行的方法，所以前面说 HashMap 很少会用到 equals。HashMap 通过 hashCode 和 equals 最终判断出 K 是否已存在，如果已存在，则使用新 V 值替换旧 V 值，并返回旧 V 值，如果不存在 ，则存放新的键值对到 bucketIndex 位置。整个 put 过程的流程图如下：\n\n相关源码如下：\n123456789101112131415161718192021222324252627282930// 在此映射中关联指定值与指定键。如果该映射以前包含了一个该键的映射关系，则旧值被替换    public V put(K key, V value) &#123;        // 当key为null，调用putForNullKey方法，保存null与table第一个位置中，这是HashMap允许为null的原因        if (key == null)            return putForNullKey(value);        // 使用hash函数预处理hashCode，计算key的hash值        int hash = hash(key.hashCode());//-------（1）        // 计算key hash 值在 table 数组中的位置        int i = indexFor(hash, table.length);//------(2)        // 从i出开始迭代 e,找到 key 保存的位置        for (Entry&lt;K, V&gt; e = table[i]; e != null; e = e.next) &#123;            Object k;            // 判断该条链上是否有hash值相同的(key相同)            // 若存在相同，则直接覆盖value，返回旧value            if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123;                // 旧值 = 新值                V oldValue = e.value;                // 将要存储的value存进去                e.value = value;                e.recordAccess(this);                // 返回旧的value                return oldValue;            &#125;        &#125;        // 修改次数增加1        modCount++;        // 将key、value添加至i位置处        addEntry(hash, key, value, i);        return null;    &#125;\n\n通过源码我们可以清晰看到 HashMap 保存数据的过程为：首先判断 key 是否为 null，若为 null，则直接调用 putForNullKey 方法。若不为空则先计算 key 的 hash 值，然后根据 hash 值搜索在 table 数组中的索引位置，如果 table 数组在该位置处有元素，则通过比较是否存在相同的 key，若存在则覆盖原来 key 的 value，否则将该元素保存在链头（最先保存的元素放在链尾）。若 table 在该处没有元素，则直接保存。这个过程看似比较简单，其实深有内幕。有如下几点：1、 先看迭代处。此处迭代原因就是为了防止存在相同的 key 值，若发现两个 hash 值（key）相同时，HashMap 的处理方式是用新 value 替换旧 value，这里并没有处理 key，这就解释了 HashMap 中没有两个相同的 key。2、 在看（1）、（2）处。这里是 HashMap 的精华所在。首先是 hash 方法，该方法为一个纯粹的数学计算，就是计算 h 的 hash 值。\nHashMap 的底层数组长度总是 2 的 n 次方，在构造函数中存在：capacity &lt;&lt;&#x3D; 1;这样做总是能够保证 HashMap 的底层数组长度为 2 的 n 次方。当 length 为 2 的 n 次方时，h&amp;(length - 1)就相当于对 length 取模，而且速度比直接取模快得多，这是 HashMap 在速度上的一个优化。这里再来复习 put 的流程：当我们想一个 HashMap 中添加一对 key-value 时，系统首先会计算 key 的 hash 值，然后根据 hash 值确认在 table 中存储的位置。若该位置没有元素，则直接插入。否则迭代该处元素链表并依此比较其 key 的 hash 值。如果两个 hash 值相等且 key 值相等(e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || key.equals(k))),则用新的 Entry 的 value 覆盖原来节点的 value。如果两个 hash 值相等但 key 值不等 ，则将该节点插入该链表的链头。具体的实现过程见 addEntry 方法，如下：\n1234567891011// 添加一个新的桶来保存该key和value    void addEntry(int hash, K key, V value, int bucketIndex) &#123;        // 获取bucketIndex处的Entry        Entry&lt;K, V&gt; e = table[bucketIndex];        // 将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry        table[bucketIndex] = new Entry&lt;K, V&gt;(hash, key, value, e);        // 若HashMap中元素的个数超过极限了，则容量扩大两倍        if (size++ &gt;= threshold)            // 调整容量            resize(2 * table.length);    &#125;\n\n这个方法中有两点需要注意：一是链的产生：系统总是将新的 Entry 对象添加到 bucketIndex 处。如果 bucketIndex 处已经有了对象，那么新添加的 Entry 对象将指向原有的 Entry 对象，形成一条 Entry 链，但是若 bucketIndex 处没有 Entry 对象，也就是 e&#x3D;&#x3D;null,那么新添加的 Entry 对象指向 null，也就不会产生 Entry 链了。二是扩容问题：随着 HashMap 中元素的数量越来越多，发生碰撞的概率就越来越大，所产生的链表长度就会越来越长，这样势必会影响 HashMap 的速度，为了保证 HashMap 的效率，系统必须要在某个临界点进行扩容处理。该临界点在当 HashMap 中元素的数量等于 table 数组长度*加载因子。但是扩容是一个非常耗时的过程，因为它需要重新计算这些数据在新 table 数组中的位置并进行复制处理。所以如果我们已经预知 HashMap 中元素的个数，那么预设元素的个数能够有效的提高 HashMap 的性能。\n六.和其他 Map 比较HashMap、ConcurrentHashMap、HashTable 的区别引入ConcurrentHashMap是为了在同步集合 HashTable 之间有更好的选择，HashTable与HashMap、ConcurrentHashMap主要的区别在于 HashMap 不是同步的、线程不安全的和不适合应用于多线程并发环境下，而ConcurrentHashMap是线程安全的集合容器，特别是在多线程和并发环境中，通常作为Map的主要实现。除了线程安全外，他们之间还有一些细微的不同，本文会介绍到。顺便说说，HashMap和ConcurrentHashMap还有ConcurrentHashMap和Hashtable两者之间的区别在 Java 面试中经常出现，特别是高级 Java 程序员。\nHashMap 与 ConcurrentHashMap 的区别在这部分，我们会看到更多关于HashMap和ConcurrentHashMap的细节和对比它们之间的参数比如线程安全、同步、性能和基本的使用。\n\n就像上面所说他们之间的第一个重要的区别就是ConcurrentHashMap是线程安全的和在并发环境下不需要加额外的同步。虽然它不像Hashtable那样需要同样的同步等级(全表锁)，但也有很多实际的用途。\n\n你可以使用Collections.synchronizedMap(HashMap)来包装 HashMap 作为同步容器，这时它的作用几乎与Hashtable一样,当每次对Map做修改操作的时候都会锁住这个Map对象，而ConcurrentHashMap会基于并发的等级来划分整个 Map 来达到线程安全，它只会锁操作的那一段数据而不是整个Map都上锁。\n\nConcurrentHashMap有很好的扩展性，在多线程环境下性能方面比做了同步的HashMap要好，但是在单线程环境下，HashMap会比ConcurrentHashMap好一点。\n\n\nConcurrentHashMap vs Hashtable vs Synchronized Map虽然三个集合类在多线程并发应用中都是线程安全的，但是他们有一个重大的差别，就是他们各自实现线程安全的方式。Hashtable是 jdk1 的一个遗弃的类，它把所有方法都加上synchronized关键字来实现线程安全。所有的方法都同步这样造成多个线程访问效率特别低。Synchronized Map与HashTable差别不大，也是在并发中作类似的操作，两者的唯一区别就是Synchronized Map没被遗弃，它可以通过使用Collections.synchronizedMap()来包装Map作为同步容器使用。\n另一方面，ConcurrentHashMap的设计有点特别，表现在多个线程操作上。它不用做外的同步的情况下默认同时允许 16 个线程读和写这个 Map 容器。因为其内部的实现剥夺了锁，使它有很好的扩展性。不像HashTable和Synchronized Map，ConcurrentHashMap不需要锁整个 Map，相反它划分了多个段(segments)，要操作哪一段才上锁那段数据。\n坦白说，集合类是一个最重要的 Java API，我觉得恰当的使用它们是一种艺术。依我个人经验，我会使用ArrayList这些容器来提高自己的 Java 程序的性能，而不会去用一些遗弃的容器比如Vector等等，在 Java 5 之前，Java 集合容器有一个很致命的缺陷就是缺乏可扩展性。同步集合类比如Hashtable和Vector在多线程 Java 应用里面逐渐成为障碍物；在 jdk5 后出现一些很好的并发集合，对大容量、低延迟的电子交易系统有很大影响，是快速存取数据的支柱。\n正确理解 Thread Local 的原理与适用场景ThreadLocal 解决什么问题由于 ThreadLocal 支持范型，如 ThreadLocal&lt; StringBuilder &gt;，为表述方便，后文用 变量 代表 ThreadLocal 本身，而用 实例 代表具体类型（如 StringBuidler ）的实例。\n不恰当的理解下面是常见的对于 ThreadLocal 的介绍\n\nThreadLocal 为解决多线程程序的并发问题提供了一种新的思路ThreadLocal 的目的是为了解决多线程访问资源时的共享问题\n\n还有很多文章在对比 ThreadLocal 与 synchronize 的异同。既然是作比较，那应该是认为这两者解决相同或类似的问题。\n上面的描述，问题在于，ThreadLocal 并不解决多线程 共享 变量的问题。既然变量不共享，那就更谈不上同步的问题。\n合理的理解ThreadLocal 变量，它的基本原理是，同一个 ThreadLocal 所包含的对象（对 ThreadLocal&lt; String &gt;而言即为 String 类型变量），在不同的 Thread 中有不同的副本（实际是不同的实例，后文会详细阐述）。这里有几点需要注意\n\n因为每个 Thread 内有自己的实例副本，且该副本只能由当前 Thread 使用。这是也是 ThreadLocal 命名的由来\n既然每个 Thread 有自己的实例副本，且其它 Thread 不可访问，那就不存在多线程间共享的问题\n既无共享，何来同步问题，又何来解决同步问题一说？\n\n那 ThreadLocal 到底解决了什么问题，又适用于什么样的场景？\n\nThis class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method) has its own, independently initialized copy of the variable. ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID).Each thread holds an implicit reference to its copy of a thread-local variable as long as the thread is alive and the ThreadLocal instance is accessible; after a thread goes away, all of its copies of thread-local instances are subject to garbage collection (unless other references to these copies exist).\n\n\nThreadLocal 提供了线程本地的实例。它与普通变量的区别在于，每个使用该变量的线程都会初始化一个完全独立的实例副本。ThreadLocal 变量通常被private static修饰。当一个线程结束时，它所使用的所有 ThreadLocal 相对的实例副本都可被回收。\n\n总的来说，ThreadLocal 适用于每个线程需要自己独立的实例且该实例需要在多个方法中被使用，也即变量在线程间隔离而在方法或类间共享的场景。后文会通过实例详细阐述该观点。另外，该场景下，并非必须使用 ThreadLocal ，其它方式完全可以实现同样的效果，只是 ThreadLocal 使得实现更简洁。\nThreadLocal 用法下面通过如下代码说明 ThreadLocal 的使用方式\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class ThreadLocalDemo &#123;  public static void main(String[] args) throws InterruptedException &#123;    int threads = 3;    CountDownLatch countDownLatch = new CountDownLatch(threads);    InnerClass innerClass = new InnerClass();    for(int i = 1; i &lt;= threads; i++) &#123;      new Thread(() -&gt; &#123;        for(int j = 0; j &lt; 4; j++) &#123;          innerClass.add(String.valueOf(j));          innerClass.print();        &#125;        innerClass.set(&quot;hello world&quot;);        countDownLatch.countDown();      &#125;, &quot;thread - &quot; + i).start();    &#125;    countDownLatch.await();  &#125;  private static class InnerClass &#123;    public void add(String newStr) &#123;      StringBuilder str = Counter.counter.get();      Counter.counter.set(str.append(newStr));    &#125;    public void print() &#123;      System.out.printf(&quot;Thread name:%s , ThreadLocal hashcode:%s, Instance hashcode:%s, Value:%s\\n&quot;,      Thread.currentThread().getName(),      Counter.counter.hashCode(),      Counter.counter.get().hashCode(),      Counter.counter.get().toString());    &#125;    public void set(String words) &#123;      Counter.counter.set(new StringBuilder(words));      System.out.printf(&quot;Set, Thread name:%s , ThreadLocal hashcode:%s,  Instance hashcode:%s, Value:%s\\n&quot;,      Thread.currentThread().getName(),      Counter.counter.hashCode(),      Counter.counter.get().hashCode(),      Counter.counter.get().toString());    &#125;  &#125;  private static class Counter &#123;    private static ThreadLocal&lt;StringBuilder&gt; counter = new ThreadLocal&lt;StringBuilder&gt;() &#123;      @Override      protected StringBuilder initialValue() &#123;        return new StringBuilder();      &#125;    &#125;;  &#125;&#125;\n\n上述代码执行结果如下\n123456789101112131415Thread name:thread - 1 , ThreadLocal hashcode:372282300, Instance hashcode:418873098, Value:0Thread name:thread - 3 , ThreadLocal hashcode:372282300, Instance hashcode:1609588821, Value:0Thread name:thread - 2 , ThreadLocal hashcode:372282300, Instance hashcode:1780437710, Value:0Thread name:thread - 3 , ThreadLocal hashcode:372282300, Instance hashcode:1609588821, Value:01Thread name:thread - 1 , ThreadLocal hashcode:372282300, Instance hashcode:418873098, Value:01Thread name:thread - 3 , ThreadLocal hashcode:372282300, Instance hashcode:1609588821, Value:012Thread name:thread - 3 , ThreadLocal hashcode:372282300, Instance hashcode:1609588821, Value:0123Set, Thread name:thread - 3 , ThreadLocal hashcode:372282300,  Instance hashcode:1362597339, Value:hello worldThread name:thread - 2 , ThreadLocal hashcode:372282300, Instance hashcode:1780437710, Value:01Thread name:thread - 1 , ThreadLocal hashcode:372282300, Instance hashcode:418873098, Value:012Thread name:thread - 2 , ThreadLocal hashcode:372282300, Instance hashcode:1780437710, Value:012Thread name:thread - 1 , ThreadLocal hashcode:372282300, Instance hashcode:418873098, Value:0123Thread name:thread - 2 , ThreadLocal hashcode:372282300, Instance hashcode:1780437710, Value:0123Set, Thread name:thread - 1 , ThreadLocal hashcode:372282300,  Instance hashcode:482932940, Value:hello worldSet, Thread name:thread - 2 , ThreadLocal hashcode:372282300,  Instance hashcode:1691922941, Value:hello world\n\n从上面的输出可看出\n\n从第 1-3 行输出可见，每个线程通过 ThreadLocal 的 get() 方法拿到的是不同的 StringBuilder 实例\n第 1-3 行输出表明，每个线程所访问到的是同一个 ThreadLocal 变量\n从 7、12、13 行输出以及第 30 行代码可见，虽然从代码上都是对 Counter 类的静态 counter 字段进行 get() 得到 StringBuilder 实例并追加字符串，但是这并不会将所有线程追加的字符串都放进同一个 StringBuilder 中，而是每个线程将字符串追加进各自的 StringBuidler 实例内\n对比第 1 行与第 15 行输出并结合第 38 行代码可知，使用 set(T t) 方法后，ThreadLocal 变量所指向的 StringBuilder 实例被替换\n\n","slug":"java/Java面试题收集整理","date":"2020-04-27T21:09:33.000Z","categories_index":"java","tags_index":"面试,java","author_index":"Gao"},{"id":"cc217f8ad2b16d80f09e9b03836cc169","title":"Github","content":"github Clone 加速\ngit config –global http.postBuffer 524288000postBuffer(智能 HTTP 传输所使用的缓冲区)\n\n修改 git 代理12345678git config --global http.proxy &#x27;http://127.0.0.1:1080&#x27;git config --global https.proxy &#x27;http://127.0.0.1:1080&#x27;# 只对github.com代理git config --global http.https://github.com.proxy socks5://127.0.0.1:1080# 取消代理git config --global --unset http.https://github.com.proxy\n\n只修改 github 的代理,不影响其他仓库\n取消代理12git config --global --unset http.proxygit config --global --unset https.proxy\n","slug":"git/github","date":"2020-04-27T21:06:28.000Z","categories_index":"git","tags_index":"github","author_index":"Gao"},{"id":"de1c13a150c1ef1c4839df0e0e3869a8","title":"Git Subtree","content":"用 Git Subtree 在多个 Git 项目间双向同步子项目，附简明使用手册转自https://tech.youzan.com/git-subtree/\n\n什么时候需要 Subtree ？1、当多个项目共用同一坨代码，而这坨代码跟着项目在快速更新的时候2、把一部分代码迁移出去独立为一个新的 git 仓库，但又希望能够保留这部分代码的历史提交记录。\n\n背景有赞微商城曾经是一个很大的前后端代码都包含在里面的 Git 项目，为了方便管理我们把前后端代码分离成 2 个 Git 仓库，进而再作分项目拆分成多个 Git 仓库。\n于是，就需要有好的方式同步各个项目共用的 Css 库、JS 库、PHP 库（他们都是以独立的 Git 仓库的形式存在）。而且由于开发节奏极快，我们需要这些库是可以在不同项目间双向同步的而不是单向同步。而且，最好能做到被迁移的这部分代码在新的 git 仓库里保留原有的历史提交记录。\n举个栗子：A 项目需要在给某个子项目 W 里添加一个文件，最方便的方式自然是直接在 A 项目里改 W 子项目对应的目录里的代码，然后测试通过后，把这个更改提交到 W 子项目的 Git 仓库里。如果这时候还要先单独更新 W 子项目的代码然后提交到 Git 服务器，再在 A 项目里把 W 子项目的代码更新过来，显然是很麻烦的，更麻烦的是如果发现代码有 bug，还得再走一遍这个流程。\n有什么方案？\nGit Submodule：这是 Git 官方以前的推荐方案\nGit Subtree：从 Git 1.5.2 开始，Git 新增并推荐使用这个功能来管理子项目\nnpm：node package manager，实际上不仅仅是 node 的包管理工具\ncomposer：暂且认为他是 php 版 npm、php 版 Maven 吧\nbower：针对浏览器前端的包管理工具（Web sites are made of lots of things — frameworks, libraries, assets, utilities, and rainbows. Bower manages all these things for you.），这东西很好用，我们在大量使用。\n\n虽然 npm、composer、maven 等更侧重于包的依赖管理，以上几个方案都是能够做到在不同项目中同步同一块代码的，但没法双向同步，更适用于子项目代码比较稳定的情形。\nGit Submodule 和 Git Subtree 都是官方支持的功能，不具有依赖管理的功能，但能满足我们的要求。Git Subtree 相对来说会更好一些 。\nGit Subtree 好在哪里用一句话来描述 Git Subtree 的优势就是：\n\n经由 Git Subtree 来维护的子项目代码，对于父项目来说是透明的，所有的开发人员看到的就是一个普通的目录，原来怎么做现在依旧那么做，只需要维护这个 Subtree 的人在合适的时候去做同步代码的操作。\n\n它是怎么做到的呢？简单说下原理\nGit Subtree 的原理首先，你有两个伟大的项目——我们叫他 P1 项目、P2 项目，还有一个牛逼的要被多个项目共用的项目——我们叫他 S 项目。我们通过简要讲解使用 Subtree 来同步代码的过程来解释 Subtree 的原理\n1、初始化子项目 Subtree通过\n1234cd P1项目的路径git subtree add --prefix=用来放S项目的相对路径 S项目git地址 xxx分支12\n\n这样的命令，把 S 项目（我们姑且叫他 S 项目）的代码下载到–prefix 所指定的目录——我们姑且叫他 S 目录把，并在 P1 项目里自动产生一个 commit（就是把 S 目录的内容提交到 P1 项目里）。\n对于 P2 项目也做同样的操作\n2、像往常一样更新代码大家在 P1 项目里各种提交 commit，其中有些 commit 会涉及到 S 目录的更改，正如前面提到的，这是没任何关系的，大家也不会感受到有任何不一样。\n3、提交更改到子项目的 Git 服务器关键的地方来了： 当维护这个 S 项目 Subtree 的人希望把最近这段时间对 S 目录的更改提交到 S 项目的 Git 服务器上时，他执行一段类似于这样的命令：\n1234cd P1项目的路径git subtree push --prefix=S项目的路径 S项目git地址 xxx分支12\n\nGit 会遍历所有的 commit，从中找出针对 S 目录的更改，然后把这些更改记录提交到 S 项目的 Git 服务器上\n4、更新子项目新的代码到父项目OK，现在 S 项目有大量的新代码了，P2 项目也想使用这些新代码，维护 P2 这个 Subtree 的人只要执行：\n123git subtree pull --prefix=S项目的路径 S项目git地址 xxx分支1\n\n这样就可以将 P2 项目里 S 项目目录里的内容更新为 S 项目 xxx 分支的最新代码了。\n我们总结的 Git Subtree 简明使用手册假设，你要在各个项目里的components&#x2F;zenjs这个目录对 http://github.com/youzan/zenjs.git 这个项目做 Subtree\n1.首先必须确保各个项目已经添加 zenjs 这个 remote（关于 remote 是什么可以看这里）:\n123git remote add zenjs http://github.com/youzan/zenjs.git1\n\n2.将 zenjs 添加到各个项目里\n123git subtree add --prefix=components/zenjs zenjs master1\n\n3.各项目更新 zenjs 代码的方法:\n123git subtree pull --prefix=components/zenjs zenjs master1\n\n4.各项目提交 zenjs 代码的方法:\n123git subtree push --prefix=components/zenjs zenjs hotfix/zenjs_xxxx1\n\n这会在远程的 zenjs 的仓库里生成一个叫 hotfix&#x2F;zenjs_xxxx 的的分支，包含了你过去对 components&#x2F;zenjs 所有的更改记录\n\n把 hotfix&#x2F;zenjs_xxx 分支更新并合并到 master 并提交\n\n这样其他工程就可以更新到你提交的代码了。\n\n有人可能会问，只用 master 分支，不管版本，太有风险了。\n对的，正如我们前面说到的那样，subtree 的方案适用的场景是：各个项目共用一个库，而这个库正在快速迭代更新的过程中。如果追求稳定，只需要给库拉出一个如 v0.1.0 这样的版本号命名的稳定分支，subtree 只用这个分支即可。\n我们现在使用的方式就是：A 项目经常会对 zenjs 做更新，所以 A 项目用 subtree 来双向同步；B 项目只是使用，所以用 bower 用来按版本来更新代码。\n\n高阶功能: 重新 split 出一个新起点（这样，每次提交 subtree 的时候就不会从头遍历一遍了）\n12git subtree split --rejoin --prefix=components/zenjs --branch new_zenjsgit push zenjs new_zenjs:master\n","slug":"git/Git-Subtree","date":"2020-04-27T19:17:06.000Z","categories_index":"git","tags_index":"git","author_index":"Gao"},{"id":"8a0a0dc1ebb478d0d6de18845129dce6","title":"Linux Config","content":"Ubuntu 初始化的一些简单配置ssh 配置\n安装 ssh\n\napt-get install opnessh-server\n\n\n如果出现错误 Connection closed by ip\n\nsudo dpkg-reconfigure openssh-server\n\n然后再重新修改一些端口等配置\n\n\n更换国内源,阿里云源感觉不是很稳定,一般用中科大的\nvim &#x2F;etc&#x2F;apt&#x2F;sources.list删除原有的\n\n替换为\n12345678910deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse\n\n\nsudo apt-get updatesudo apt-get upgrade\n\n安装 zsh\nsudo apt-get install zsh\n\n\nchsh -s &#x2F;bin&#x2F;zsh\n\n\nsudo apt-get install git\n\n配置 git\n配置个人信息\n\n12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot;\n\n\n生成 SSH\n\n\n$ ssh-keygen -t rsa -C “&#x79;&#x6f;&#x75;&#x72;&#101;&#x6d;&#x61;&#105;&#x6c;&#x40;&#101;&#x78;&#x61;&#109;&#x70;&#x6c;&#x65;&#46;&#99;&#x6f;&#109;“\n\n\nsh -c “$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)”\n\n\n更换主题 agnoster\n\n安装 nodejs\n安装最新 nodejs 方法\n\n\ncurl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash -sudo apt-get install -y nodejs\n\n替换 npm 源1.临时使用\n\nnpm –registry https://registry.npm.taobao.org install express\n\n2.持久使用\n\nnpm config set registry https://registry.npm.taobao.org&#x2F;&#x2F; 配置后可通过下面方式来验证是否成功npm config get registry&#x2F;&#x2F; 或npm info express\n\n3.通过 cnpm 使用\n\nnpm install -g cnpm –registry&#x3D;https://registry.npm.taobao.org&#x2F;&#x2F; 使用cnpm install expresstall express\n\nCentos 一些配置ifconfig command not found\nyum install net-tools\n\n","slug":"Linux-Config","date":"2020-04-20T01:23:36.000Z","categories_index":"系统","tags_index":"Linux","author_index":"Gao"}]